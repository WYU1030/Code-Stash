{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61feddcd",
   "metadata": {},
   "source": [
    "#### Homework2\n",
    "Please explain clearly and include your entire computational work when needed. Should you include any code, please make sure to provide additional comments to explain your solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe85ed4",
   "metadata": {},
   "source": [
    "Q1 (8 points) Answer the following questions clearly. \n",
    "- (4 points) Compare the cost functions in Ridge and Lasso Regression and indicate the regularization parameter. \n",
    "\n",
    "- (4 points) Explain which weights are more penalized in Ridge Regression and why (discuss your answer in the context of constraint satisfaction and take into account the constraint on Ridge Regression coefficients). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e43dd04",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdac371d",
   "metadata": {},
   "source": [
    "Q2 (12 points) In the context of training a linear regression model using Maximum-Likelihood-Estimation, answer the following questions:\n",
    "- (4 points) Indicate all assumptions discussed in the lecture under the MLE principle about the data, residual error, and the type of the probability density function used in the Likelihood function. \n",
    "- (4 points) Indicate the Likelihood function mathematically with respect to the assumptions made under MLE principle, and describe each term/parameters used in the likelihood function. \n",
    "- (4 points) Explain how the concept of maximizing the likelihood of observing data under model parameters is convertible to minimizing the NLL? Discuss in terms of the mathematical notation and the shape of the function. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d067c09",
   "metadata": {},
   "source": [
    "Q3 (10 points) Use the sklearn Breast_cancer dataset and use min-max scalar to transform the input attributes. Next, develop two classifiers using logistic regression, and perceptron learning. Train on the training data (75% of the entire data) and compare the performance of the models by reporting accuracy \"accuracy = accuracy_score(y_test, y_pred). Which model performs better? Support your answer by providing plots of the decision boundary (hint: is the decision boundary indicative of linearly separable data?). Provide your coding for the developed models and document your code. Failing proper documentation leads to losing points. Necessary library functions are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa7efb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ac737a",
   "metadata": {},
   "source": [
    "Q4 (6 points) Compare and contrast Newton's method and gradient descent as optimization algorithms for finding the minimum of a function. Provide insights into their convergence properties, computational complexities, and practical considerations. Discuss situations where Newton's method should not be used. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b08c1f2",
   "metadata": {},
   "source": [
    "Q5 (6 points) Mathematically explain how a perceptron learning model is trained. Discuss in terms of the gradient of the error function used in Perceptron Learning algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56f0128",
   "metadata": {},
   "source": [
    "Q6 (4 points) Compare a Perceptron Learning algorithm with \"Binary Step function\" used as activation function, with a linear regression function in the context of binary classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5219f68",
   "metadata": {},
   "source": [
    "Q7 (10 points) Answer the following questions: \n",
    "- (6 points) Discuss the vanishing gradient problem in the context of training deep neural networks and identify activation functions that are particularly susceptible to this phenomenon. \n",
    "  \n",
    "- (4 points) Explain why these activation functions lead to vanishing gradients during backpropagation (hint: discuss in terms of the shape of the activation function). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b950753",
   "metadata": {},
   "source": [
    "Q8 (10 points) List all hyperparameters discussed in the class related to Artificial and Deep Neural Networks and explain the role/impact of each hyperparameter. Which technique(s) can be used to perform hyperparameter tuning? Explain how the technique(s) work.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa57235d",
   "metadata": {},
   "source": [
    "Q9 (20 points) Given a dataset with input attributes x1 and x2, and output variable y, you are training a 3 layer neural network. Assume that activation function used in each layer is sigmoid. Mathematically describe one feed-forward pass followed by one backward-pass in terms of updating the weights of each layer in this neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c7de4e",
   "metadata": {},
   "source": [
    "Q10 (14 points) In this exercise, use the output information generated by this code to perform a comparative study of the performance (i.e., loss , Accuracy) of the neural networks models based on the hyperparameters used. Generate a table to report your analysis.\n",
    "Note: If you want to run this code and have trouble with imported libraries, try 'pip install keras==2.12.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06e38d71",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SGD\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasClassifier\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[0;32m     13\u001b[0m digits \u001b[38;5;241m=\u001b[39m load_digits()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.wrappers'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Load dataset\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# Preprocess data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define create_model function for KerasClassifier\n",
    "def create_model(num_layers=1, num_neurons=64, activation='relu', dropout_rate=0.0, momentum=0.9):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_neurons, input_dim=X_scaled.shape[1], activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(num_neurons, activation=activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    optimizer = SGD(learning_rate=0.01, momentum=momentum)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define parameters grid for grid search\n",
    "param_grid = {\n",
    "    'num_layers': [3],\n",
    "    'num_neurons': [32, 64],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'dropout_rate': [0.2, 0.5],\n",
    "    'momentum': [0.5, 0.9]\n",
    "}\n",
    "\n",
    "# Create KerasClassifier wrapper for scikit-learn\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=kfold, scoring='accuracy')\n",
    "grid_result = grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Print results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, std, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55c2190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
